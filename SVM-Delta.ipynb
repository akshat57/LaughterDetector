{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"\"\n",
    "CATEGORIES = [\"Segmented_Laugh\", \"Segmented_NonLaugh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   2,   3,   4],\n",
       "       [100, 200, 300, 400]], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3, 4], [10, 20, 30, 40], [100, 200, 300, 400]], np.int32)\n",
    "a[[0,2],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For choosing MORE THAN ONE particular MFCC'S\n",
    "n_mfcc = 3\n",
    "training_data = []\n",
    "def create_training_data():\n",
    "    count=0\n",
    "    error_count = 0\n",
    "    #Enter time in seconds\n",
    "    t_window = 1\n",
    "    t_frame = 0.025\n",
    "    t_shift = 0.01\n",
    "    n_mfccs = n_mfcc\n",
    "    laugh_counter = 0\n",
    "    nonlaugh_counter = 0\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category) \n",
    "        class_num = CATEGORIES.index(category)\n",
    "        print('New Folder')\n",
    "        for aud in os.listdir(path):\n",
    "            if aud == '.DS_Store':\n",
    "                continue\n",
    "            \n",
    "            aud_array , sr = librosa.load(os.path.join(path,aud), sr=None)\n",
    "            count+=1\n",
    "\n",
    "            mfccs = []\n",
    "            \n",
    "            try:\n",
    "                mfcc = (librosa.feature.mfcc(aud_array, sr=sr,  n_mfcc=20,  win_length = int(sr*t_frame), hop_length = int(sr*t_shift))) \n",
    "                mfcc_temp = mfcc[[0,2,6],:]\n",
    "                #mfcc_delta = librosa.feature.delta(mfcc_temp)\n",
    "                \n",
    "                mean_mfccs = np.mean(np.asarray(mfcc_temp),axis = 1)\n",
    "                var_mfccs = np.var(np.asarray(mfcc_temp), axis = 1)\n",
    "                #std_deltamfccs = np.std(np.asarray(mfcc_delta), axis = 1)\n",
    "                \n",
    "                mfccs.append(mean_mfccs)\n",
    "                mfccs.append(var_mfccs)\n",
    "                #mfccs.append(std_deltamfccs)\n",
    "                mfccs = np.asarray(mfccs).reshape(n_mfccs*2,1)\n",
    "                training_data.append([mfccs.reshape(-1,1), class_num])\n",
    "                if category == 'Segmented_Laugh':\n",
    "                    laugh_counter +=1\n",
    "                else:\n",
    "                    nonlaugh_counter += 1\n",
    "\n",
    "            except ValueError:\n",
    "                print(\"Oops!  That was no valid number.  Try again...\")\n",
    "        \n",
    "    print(laugh_counter, nonlaugh_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For choosing ONE particular MFCC'S\n",
    "n_mfcc = 1\n",
    "training_data = []\n",
    "def create_training_data():\n",
    "    count=0\n",
    "    error_count = 0\n",
    "    #Enter time in seconds\n",
    "    t_window = 1\n",
    "    t_frame = 0.025\n",
    "    t_shift = 0.01\n",
    "    n_mfccs = n_mfcc\n",
    "    laugh_counter = 0\n",
    "    nonlaugh_counter = 0\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category) \n",
    "        class_num = CATEGORIES.index(category)\n",
    "        print('New Folder')\n",
    "        for aud in os.listdir(path):\n",
    "            if aud == '.DS_Store':\n",
    "                continue\n",
    "            \n",
    "            aud_array , sr = librosa.load(os.path.join(path,aud), sr=None)\n",
    "            count+=1\n",
    "\n",
    "            mfccs = []\n",
    "            \n",
    "            try:\n",
    "                mfcc = (librosa.feature.mfcc(aud_array, sr=sr,  n_mfcc=20,  win_length = int(sr*t_frame), hop_length = int(sr*t_shift))) \n",
    "                mfcc_temp = mfcc[0,:]\n",
    "                #mfcc_delta = librosa.feature.delta(mfcc_temp)\n",
    "                \n",
    "                mean_mfccs = np.mean(np.asarray(mfcc_temp),axis = 0)\n",
    "                var_mfccs = np.var(np.asarray(mfcc_temp), axis = 0)\n",
    "                #std_deltamfccs = np.std(np.asarray(mfcc_delta), axis = 1)\n",
    "                \n",
    "                mfccs.append(mean_mfccs)\n",
    "                mfccs.append(var_mfccs)\n",
    "                #mfccs.append(std_deltamfccs)\n",
    "                mfccs = np.asarray(mfccs).reshape(n_mfccs*2,1)\n",
    "                training_data.append([mfccs.reshape(-1,1), class_num])\n",
    "                if category == 'Segmented_Laugh':\n",
    "                    laugh_counter +=1\n",
    "                else:\n",
    "                    nonlaugh_counter += 1\n",
    "\n",
    "            except ValueError:\n",
    "                print(\"Oops!  That was no valid number.  Try again...\")\n",
    "        \n",
    "    print(laugh_counter, nonlaugh_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For choosing ONE particular MFCC'S\n",
    "n_mfcc = 1\n",
    "training_data = []\n",
    "def create_training_data():\n",
    "    count=0\n",
    "    error_count = 0\n",
    "    #Enter time in seconds\n",
    "    t_window = 1\n",
    "    t_frame = 0.025\n",
    "    t_shift = 0.01\n",
    "    n_mfccs = n_mfcc\n",
    "    laugh_counter = 0\n",
    "    nonlaugh_counter = 0\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category) \n",
    "        class_num = CATEGORIES.index(category)\n",
    "        print('New Folder')\n",
    "        for aud in os.listdir(path):\n",
    "            if aud == '.DS_Store':\n",
    "                continue\n",
    "            \n",
    "            aud_array , sr = librosa.load(os.path.join(path,aud), sr=None)\n",
    "            count+=1\n",
    "\n",
    "            mfccs = []\n",
    "            \n",
    "            try:\n",
    "                mfcc = (librosa.feature.mfcc(aud_array, sr=sr,  n_mfcc=20,  win_length = int(sr*t_frame), hop_length = int(sr*t_shift))) \n",
    "                mfcc_temp = mfcc[0,:]\n",
    "                mfcc_delta = librosa.feature.delta(mfcc_temp)\n",
    "                \n",
    "                #mean_mfccs = np.mean(np.asarray(mfcc_temp),axis = 0)\n",
    "                #var_mfccs = np.var(np.asarray(mfcc_temp), axis = 0)\n",
    "                mean_deltamfccs = np.std(np.asarray(mfcc_delta), axis = 0)\n",
    "                std_deltamfccs = np.std(np.asarray(mfcc_delta), axis = 0)\n",
    "                \n",
    "                #mfccs.append(mean_mfccs)\n",
    "                #mfccs.append(var_mfccs)\n",
    "                mfccs.append(mean_deltamfccs)\n",
    "                mfccs.append(std_deltamfccs)\n",
    "                mfccs = np.asarray(mfccs).reshape(n_mfccs*2,1)\n",
    "                training_data.append([mfccs.reshape(-1,1), class_num])\n",
    "                if category == 'Segmented_Laugh':\n",
    "                    laugh_counter +=1\n",
    "                else:\n",
    "                    nonlaugh_counter += 1\n",
    "\n",
    "            except ValueError:\n",
    "                print(\"Oops!  That was no valid number.  Try again...\")\n",
    "        \n",
    "    print(laugh_counter, nonlaugh_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Folder\n",
      "New Folder\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "Oops!  That was no valid number.  Try again...\n",
      "1678 1676\n"
     ]
    }
   ],
   "source": [
    "create_training_data()\n",
    "data = np.array(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcc array | class\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each row has 96 features(mfcc matrix)\n",
    "data[0,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3354, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "\n",
    "    \n",
    "X = np.array(X).reshape(-1,n_mfcc*2)\n",
    "#-1 corresponds to how many features we have\n",
    "Y = np.array(Y)\n",
    "#X = X/250\n",
    "#print(X.shape)\n",
    "#print(Y)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data split for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = svm.SVC(kernel='linear')\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[140  33]\n",
      " [ 89  74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.70       173\n",
      "           1       0.69      0.45      0.55       163\n",
      "\n",
      "    accuracy                           0.64       336\n",
      "   macro avg       0.65      0.63      0.62       336\n",
      "weighted avg       0.65      0.64      0.62       336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "#tn, fp, fn, tp = confusion_matrix(y_test,y_pred, labels=[0,1])\n",
    "print(confusion_matrix(y_test,y_pred, labels=[0,1]))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 53 122]\n",
      " [ 28 133]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classificat0ion_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-becdda0c5cf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#tn, fp, fn, tp = confusion_matrix(y_test,y_pred, labels=[0,1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassificat0ion_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'classificat0ion_report' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "#tn, fp, fn, tp = confusion_matrix(y_test,y_pred, labels=[0,1])\n",
    "print(confusion_matrix(y_test,y_pred, labels=[0,1]))\n",
    "print(classificat0ion_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing it against test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "chosenclass = 0\n",
    "for y in y_test:\n",
    "    if y == chosenclass:\n",
    "        total += 1\n",
    "        #if y_pred[counter]== y:\n",
    "         #   correct += 1\n",
    "    counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
